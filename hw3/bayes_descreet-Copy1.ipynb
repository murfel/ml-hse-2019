{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "import sklearn.linear_model\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import *\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = '../datasets/smsspam.csv'\n",
    "data = pd.read_csv(DATASET, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenize(text):\n",
    "    text = list(filter(lambda x: x not in ',.?!', text.lower()))\n",
    "    return ''.join(text).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = defaultdict(int)\n",
    "for index, row in data.iterrows():\n",
    "    text = row['text']\n",
    "    cur_words = my_tokenize(text)\n",
    "    for w in cur_words:\n",
    "        words[w] += 1\n",
    "words = [key for key, val in words.items() if val >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "for index, row in data.iterrows():\n",
    "    text = row['text']\n",
    "    cur_words = my_tokenize(text)\n",
    "    new_row = [0 if row['label'] == 'ham' else 1]\n",
    "    for word in words:\n",
    "        new_row.append(cur_words.count(word))\n",
    "    new_data.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(new_data, columns = ['label'] + words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_joint_log_likelihood(data):\n",
    "    values_counts = [[], []]\n",
    "    for number in [0,1]:\n",
    "        for feature in data.drop('label', axis=1):\n",
    "            feature_values = data[data['label'] == number][feature]\n",
    "            values_counts[number].append(feature_values.value_counts())\n",
    "    \n",
    "    def formula(v, vc, vc0, vc1):\n",
    "        return math.log(vc.get(v, 0) + 1) - math.log(vc0.get(v, 0) + vc1.get(v, 0) + 1)\n",
    "    \n",
    "    ans = [[], []]\n",
    "    for number in [0, 1]:\n",
    "        for index, row in data.iterrows():\n",
    "            ans[number].append(0)\n",
    "            for value_index, value in enumerate(row.drop('label')):\n",
    "                ans[number][index] += formula(value,\n",
    "                                              values_counts[number][value_index],\n",
    "                                              values_counts[0][value_index],\n",
    "                                              values_counts[1][value_index])\n",
    "    return ans\n",
    "\n",
    "def plot(jll, label):\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(\n",
    "        label,\n",
    "        [jll[1][i] - jll[0][i] for i in range(len(jll[0]))])\n",
    "    plt.plot(fpr, tpr, 'b-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jll = calc_joint_log_likelihood(data)\n",
    "plot(jll, data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
